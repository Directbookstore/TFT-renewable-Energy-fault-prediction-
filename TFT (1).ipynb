{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFnuUfr_cSsB",
        "outputId": "4ae8c8b5-05b8-49ac-b5ff-17e655ec0d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-forecasting\n",
            "  Downloading pytorch_forecasting-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from pytorch-forecasting) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (71.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.8)\n",
            "Downloading pytorch_forecasting-1.1.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.4.2-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning, pytorch-forecasting\n",
            "Successfully installed lightning-2.4.0 lightning-utilities-0.11.7 pytorch-forecasting-1.1.1 pytorch-lightning-2.4.0 torchmetrics-1.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-forecasting pytorch-lightning scikit-learn pandas torch numpy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data.encoders import GroupNormalizer\n",
        "from pytorch_lightning import Trainer"
      ],
      "metadata": {
        "id": "moHHmwGsck0I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/smart_grid_stability_augmented.csv\")\n"
      ],
      "metadata": {
        "id": "qy1rAlvceOtV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "u9RL36Byev1F",
        "outputId": "0bd1d5e9-7929-4770-970a-29f96634e1fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
              "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
              "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
              "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
              "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
              "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
              "\n",
              "         p4        g1        g2        g3        g4      stab     stabf  \n",
              "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
              "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
              "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
              "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
              "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ade6bdc-d1f9-4fe6-83a5-138c14f8d4ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tau1</th>\n",
              "      <th>tau2</th>\n",
              "      <th>tau3</th>\n",
              "      <th>tau4</th>\n",
              "      <th>p1</th>\n",
              "      <th>p2</th>\n",
              "      <th>p3</th>\n",
              "      <th>p4</th>\n",
              "      <th>g1</th>\n",
              "      <th>g2</th>\n",
              "      <th>g3</th>\n",
              "      <th>g4</th>\n",
              "      <th>stab</th>\n",
              "      <th>stabf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.959060</td>\n",
              "      <td>3.079885</td>\n",
              "      <td>8.381025</td>\n",
              "      <td>9.780754</td>\n",
              "      <td>3.763085</td>\n",
              "      <td>-0.782604</td>\n",
              "      <td>-1.257395</td>\n",
              "      <td>-1.723086</td>\n",
              "      <td>0.650456</td>\n",
              "      <td>0.859578</td>\n",
              "      <td>0.887445</td>\n",
              "      <td>0.958034</td>\n",
              "      <td>0.055347</td>\n",
              "      <td>unstable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.304097</td>\n",
              "      <td>4.902524</td>\n",
              "      <td>3.047541</td>\n",
              "      <td>1.369357</td>\n",
              "      <td>5.067812</td>\n",
              "      <td>-1.940058</td>\n",
              "      <td>-1.872742</td>\n",
              "      <td>-1.255012</td>\n",
              "      <td>0.413441</td>\n",
              "      <td>0.862414</td>\n",
              "      <td>0.562139</td>\n",
              "      <td>0.781760</td>\n",
              "      <td>-0.005957</td>\n",
              "      <td>stable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.971707</td>\n",
              "      <td>8.848428</td>\n",
              "      <td>3.046479</td>\n",
              "      <td>1.214518</td>\n",
              "      <td>3.405158</td>\n",
              "      <td>-1.207456</td>\n",
              "      <td>-1.277210</td>\n",
              "      <td>-0.920492</td>\n",
              "      <td>0.163041</td>\n",
              "      <td>0.766689</td>\n",
              "      <td>0.839444</td>\n",
              "      <td>0.109853</td>\n",
              "      <td>0.003471</td>\n",
              "      <td>unstable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.716415</td>\n",
              "      <td>7.669600</td>\n",
              "      <td>4.486641</td>\n",
              "      <td>2.340563</td>\n",
              "      <td>3.963791</td>\n",
              "      <td>-1.027473</td>\n",
              "      <td>-1.938944</td>\n",
              "      <td>-0.997374</td>\n",
              "      <td>0.446209</td>\n",
              "      <td>0.976744</td>\n",
              "      <td>0.929381</td>\n",
              "      <td>0.362718</td>\n",
              "      <td>0.028871</td>\n",
              "      <td>unstable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.134112</td>\n",
              "      <td>7.608772</td>\n",
              "      <td>4.943759</td>\n",
              "      <td>9.857573</td>\n",
              "      <td>3.525811</td>\n",
              "      <td>-1.125531</td>\n",
              "      <td>-1.845975</td>\n",
              "      <td>-0.554305</td>\n",
              "      <td>0.797110</td>\n",
              "      <td>0.455450</td>\n",
              "      <td>0.656947</td>\n",
              "      <td>0.820923</td>\n",
              "      <td>0.049860</td>\n",
              "      <td>unstable</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ade6bdc-d1f9-4fe6-83a5-138c14f8d4ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ade6bdc-d1f9-4fe6-83a5-138c14f8d4ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ade6bdc-d1f9-4fe6-83a5-138c14f8d4ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7591696d-038c-4679-85dd-933ac9da5f35\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7591696d-038c-4679-85dd-933ac9da5f35')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7591696d-038c-4679-85dd-933ac9da5f35 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 60000,\n  \"fields\": [\n    {\n      \"column\": \"tau1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7424340969997982,\n        \"min\": 0.500793021360319,\n        \"max\": 9.99946946943287,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          1.95313593543868,\n          4.61368973820627,\n          2.73800097820337\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tau2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7424369431767,\n        \"min\": 0.500141360493773,\n        \"max\": 9.99983655621537,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          2.17139235609864,\n          7.60146808205807,\n          5.37588648763036\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tau3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7424369431767,\n        \"min\": 0.500141360493773,\n        \"max\": 9.99983655621537,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          6.49691553928642,\n          4.24023359736895,\n          9.23510482728911\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tau4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7424369431767,\n        \"min\": 0.500141360493773,\n        \"max\": 9.99983655621537,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          7.49094495048652,\n          8.04373234775131,\n          4.62480877383408\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7521287637246854,\n        \"min\": 1.58258966481528,\n        \"max\": 5.8644179596283,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          5.12895219385475,\n          4.65563071827631,\n          5.00760988957757\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43301693634416,\n        \"min\": -1.99994466917731,\n        \"max\": -0.500024528740323,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          -1.56546755923411,\n          -1.59799118832529,\n          -1.07112554088676\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43301693634416,\n        \"min\": -1.99994466917731,\n        \"max\": -0.500024528740323,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          -1.78492831105981,\n          -1.31918744343427,\n          -0.919830481613649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43301693634416,\n        \"min\": -1.99994466917731,\n        \"max\": -0.500024528740323,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          -1.46545250895597,\n          -1.13855743317693,\n          -1.96079646464146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"g1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2742441042086802,\n        \"min\": 0.050009303611129,\n        \"max\": 0.999937073063054,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          0.487235135690853,\n          0.395106209672631,\n          0.162309940134343\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"g2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2742434260027031,\n        \"min\": 0.050028493958976,\n        \"max\": 0.999981832400081,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.719611844634196,\n          0.925068873389395,\n          0.849056632338181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"g3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.274243426002703,\n        \"min\": 0.050028493958976,\n        \"max\": 0.999981832400081,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.495036222584228,\n          0.765132855235613,\n          0.086293409565964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"g4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.274243426002703,\n        \"min\": 0.050028493958976,\n        \"max\": 0.999981832400081,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.372501750549654,\n          0.888738455707346,\n          0.63259017856413\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stab\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03691749401603404,\n        \"min\": -0.080759892416024,\n        \"max\": 0.109403206284885,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          0.035628965735259,\n          0.002382645768415,\n          0.030619959808307\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stabf\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"stable\",\n          \"unstable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMiF_rYXfKJX",
        "outputId": "dc67cc77-91ab-4b3e-8642-4e303c4320b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau1     0\n",
            "tau2     0\n",
            "tau3     0\n",
            "tau4     0\n",
            "p1       0\n",
            "p2       0\n",
            "p3       0\n",
            "p4       0\n",
            "g1       0\n",
            "g2       0\n",
            "g3       0\n",
            "g4       0\n",
            "stab     0\n",
            "stabf    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It shows that no missing value in this dataset"
      ],
      "metadata": {
        "id": "sF_ruoRvfyKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "num_cols = ['tau1', 'tau2', 'tau3', 'tau4', 'p1', 'p2', 'p3', 'p4', 'g1', 'g2', 'g3', 'g4', 'stab']\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# Encode the categorical 'stabf' column\n",
        "le = LabelEncoder()\n",
        "df['stabf'] = le.fit_transform(df['stabf'])  # 0 for unstable, 1 for stable\n",
        "\n",
        "# Split into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "5kj_yuFOfnG9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "\n",
        "# IQR is the difference between Q3 and Q1\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Identify outliers\n",
        "outliers = df[((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "print(outliers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixMZEPWYhP4U",
        "outputId": "fd4a08a3-8f81-44b8-8e8a-ab37861036bf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
            "6273   0.528043  0.952138  1.489009 -1.026856 -2.881725  1.723122  1.566876   \n",
            "16273  0.528043 -1.026856  0.952138  1.489009 -2.881725  1.715415  1.723122   \n",
            "26273  0.528043  1.489009 -1.026856  0.952138 -2.881725  1.566876  1.715415   \n",
            "36273  0.528043  0.952138 -1.026856  1.489009 -2.881725  1.723122  1.715415   \n",
            "46273  0.528043 -1.026856  1.489009  0.952138 -2.881725  1.715415  1.566876   \n",
            "56273  0.528043  1.489009  0.952138 -1.026856 -2.881725  1.566876  1.723122   \n",
            "\n",
            "             p4        g1        g2        g3        g4      stab  stabf  \n",
            "6273   1.715415  0.425731  1.251373 -0.112029 -0.416912  1.115803      1  \n",
            "16273  1.566876  0.425731 -0.416912  1.251373 -0.112029  1.115803      1  \n",
            "26273  1.723122  0.425731 -0.112029 -0.416912  1.251373  1.115803      1  \n",
            "36273  1.566876  0.425731  1.251373 -0.416912 -0.112029  1.115803      1  \n",
            "46273  1.723122  0.425731 -0.416912 -0.112029  1.251373  1.115803      1  \n",
            "56273  1.715415  0.425731 -0.112029  1.251373 -0.416912  1.115803      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(df['p1'], df['p2'])\n",
        "plt.title('Scatter plot between p1 and p2')\n",
        "plt.xlabel('p1')\n",
        "plt.ylabel('p2')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ElW-ySENiGHL",
        "outputId": "2127a4a1-7e47-47a8-d7de-71f867e282ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Calculate Z-scores for each feature\n",
        "z_scores = np.abs(stats.zscore(df))\n",
        "\n",
        "# Identify outliers as those with a Z-score greater than 3\n",
        "outliers = df[(z_scores > 3).any(axis=1)]\n",
        "\n",
        "print(outliers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KJDopY0ikMg",
        "outputId": "93841d24-a61d-454c-b70b-f71197d63ba9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [tau1, tau2, tau3, tau4, p1, p2, p3, p4, g1, g2, g3, g4, stab, stabf]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(outliers))  # Check how many rows are identified as outliers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8bRrDoKiv1u",
        "outputId": "f22b1b25-fb2c-4fae-d68d-10396b11fce6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it shows that the Dataset doest not have outlier"
      ],
      "metadata": {
        "id": "pEnEovvXjd5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "HK8LDcFmjErQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_forecasting import TimeSeriesDataSet\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeHGzyj5kbgF",
        "outputId": "5d26014a-fe15-488f-854b-60e9ea8307b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
            "tau1   1.000000 -0.002550 -0.002550 -0.002550  0.027183 -0.015739 -0.015739   \n",
            "tau2  -0.002550  1.000000  0.005554  0.005554  0.003004 -0.004473 -0.000372   \n",
            "tau3  -0.002550  0.005554  1.000000  0.005554  0.003004 -0.000372 -0.004473   \n",
            "tau4  -0.002550  0.005554  0.005554  1.000000  0.003004 -0.000372 -0.000372   \n",
            "p1     0.027183  0.003004  0.003004  0.003004  1.000000 -0.578983 -0.578983   \n",
            "p2    -0.015739 -0.004473 -0.000372 -0.000372 -0.578983  1.000000  0.002833   \n",
            "p3    -0.015739 -0.000372 -0.004473 -0.000372 -0.578983  0.002833  1.000000   \n",
            "p4    -0.015739 -0.000372 -0.000372 -0.004473 -0.578983  0.002833  0.002833   \n",
            "g1     0.010521 -0.005832 -0.005832 -0.005832  0.000721 -0.000417 -0.000417   \n",
            "g2     0.006522  0.009865  0.002102  0.002102  0.000341 -0.002141  0.000774   \n",
            "g3     0.006522  0.002102  0.009865  0.002102  0.000341  0.000774 -0.002141   \n",
            "g4     0.006522  0.002102  0.002102  0.009865  0.000341  0.000774  0.000774   \n",
            "stab   0.275761  0.283417  0.283417  0.283417  0.010278 -0.005951 -0.005951   \n",
            "stabf  0.234898  0.241049  0.241049  0.241049  0.009938 -0.005754 -0.005754   \n",
            "\n",
            "             p4        g1        g2        g3        g4      stab     stabf  \n",
            "tau1  -0.015739  0.010521  0.006522  0.006522  0.006522  0.275761  0.234898  \n",
            "tau2  -0.000372 -0.005832  0.009865  0.002102  0.002102  0.283417  0.241049  \n",
            "tau3  -0.000372 -0.005832  0.002102  0.009865  0.002102  0.283417  0.241049  \n",
            "tau4  -0.004473 -0.005832  0.002102  0.002102  0.009865  0.283417  0.241049  \n",
            "p1    -0.578983  0.000721  0.000341  0.000341  0.000341  0.010278  0.009938  \n",
            "p2     0.002833 -0.000417 -0.002141  0.000774  0.000774 -0.005951 -0.005754  \n",
            "p3     0.002833 -0.000417  0.000774 -0.002141  0.000774 -0.005951 -0.005754  \n",
            "p4     1.000000 -0.000417  0.000774  0.000774 -0.002141 -0.005951 -0.005754  \n",
            "g1    -0.000417  1.000000  0.004718  0.004718  0.004718  0.282774  0.197664  \n",
            "g2     0.000774  0.004718  1.000000 -0.006939 -0.006939  0.293684  0.218015  \n",
            "g3     0.000774  0.004718 -0.006939  1.000000 -0.006939  0.293684  0.218015  \n",
            "g4    -0.002141  0.004718 -0.006939 -0.006939  1.000000  0.293684  0.218015  \n",
            "stab  -0.005951  0.282774  0.293684  0.293684  0.293684  1.000000  0.826959  \n",
            "stabf -0.005754  0.197664  0.218015  0.218015  0.218015  0.826959  1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6RrkGiDk4hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Insights\n",
        "Time Columns (tau1, tau2, tau3, tau4):\n",
        "\n",
        "These columns have very low correlations with each other, indicating they are likely not collinear.\n",
        "They also have low correlation with p columns, g columns, and the target variables (stab and stabf), suggesting that the time columns may have limited influence on these variables.\n",
        "Parameters (p1, p2, p3, p4):\n",
        "\n",
        "There is a strong negative correlation between p1 and the other p columns, suggesting that these parameters are inversely related.\n",
        "p1 has a low correlation with stab and stabf, implying it might not be a significant predictor for these outcomes.\n",
        "G Columns (g1, g2, g3, g4):\n",
        "\n",
        "These columns have relatively low correlations with each other but have moderate correlations with stab and stabf, indicating they may play a more substantial role in predicting these outcomes compared to the tau and p columns.\n",
        "Target Variables (stab, stabf):\n",
        "\n",
        "Both stab and stabf show strong positive correlations with each other.\n",
        "The stab and stabf columns have significant correlations with the g columns, suggesting that g columns might be important predictors for these target variables."
      ],
      "metadata": {
        "id": "-mWFDWTqmWYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRblyOsomZCe",
        "outputId": "e06da261-2ae9-4192-ca09-1be57eb48a3f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['tau1', 'tau2', 'tau3', 'tau4', 'p1', 'p2', 'p3', 'p4', 'g1', 'g2',\n",
            "       'g3', 'g4', 'stab', 'stabf'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex7hy0gQnwz9",
        "outputId": "ca2ef556-e082-49a5-bde1-815b96099489"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
            "48572  1.129543  1.726514  1.059525  0.687641  1.257212 -1.493692 -1.040221   \n",
            "38696  1.693901 -0.011534 -1.531814 -1.225373 -1.190822  1.298100  1.629712   \n",
            "13611  0.931985 -1.394627 -0.591586  0.626323 -0.957030  1.087540 -0.896396   \n",
            "35213  0.914392 -1.569813  1.595629  0.763249  0.809421 -1.477911  1.086703   \n",
            "31766 -1.651294 -0.995641  0.089400  0.948869  1.887863 -0.707468 -0.963545   \n",
            "\n",
            "             p4        g1        g2        g3        g4      stab  stabf  \n",
            "48572  0.350199  1.530448  1.616867 -0.244457  0.848759  2.118736      1  \n",
            "38696 -0.859414 -0.452117 -0.431227 -0.689044  0.501455 -1.575823      0  \n",
            "13611  1.471169 -0.601180  1.110587 -0.884969 -1.625643 -1.279109      0  \n",
            "35213 -1.014716 -0.876993 -1.270139 -0.833456 -1.243011 -1.106973      0  \n",
            "31766 -1.608110 -0.607596 -0.716800 -0.264250  1.662188 -0.021873      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oTxLxb8doYpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " it seems you have a DataFrame with various columns, but no explicit time column listed. To use TimeSeriesDataSet in PyTorch Forecasting, you need to include a time index column to represent the time steps in your data."
      ],
      "metadata": {
        "id": "73UPMOrepSvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Add a sequential time index\n",
        "train_df['time_index'] = range(len(train_df))\n"
      ],
      "metadata": {
        "id": "1IFY7ofppVqG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnBF2s9ppe7d",
        "outputId": "239a774d-246a-45e3-abdc-77ce74ac7c7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['tau1', 'tau2', 'tau3', 'tau4', 'p1', 'p2', 'p3', 'p4', 'g1', 'g2',\n",
            "       'g3', 'g4', 'stab', 'stabf', 'time_index'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"time_index\"] = pd.to_datetime(train_df[\"time_index\"])  # If it's datetime\n",
        "# Or\n",
        "train_df[\"time_index\"] = train_df[\"time_index\"].astype(int)  # If it's integer\n"
      ],
      "metadata": {
        "id": "fAZ8rYSgpv2x"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "print(train_df.columns)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xonS9f7kqvM2",
        "outputId": "ac807b64-5d4e-45a6-fcb7-14e55e554b0b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
            "48572  1.129543  1.726514  1.059525  0.687641  1.257212 -1.493692 -1.040221   \n",
            "38696  1.693901 -0.011534 -1.531814 -1.225373 -1.190822  1.298100  1.629712   \n",
            "13611  0.931985 -1.394627 -0.591586  0.626323 -0.957030  1.087540 -0.896396   \n",
            "35213  0.914392 -1.569813  1.595629  0.763249  0.809421 -1.477911  1.086703   \n",
            "31766 -1.651294 -0.995641  0.089400  0.948869  1.887863 -0.707468 -0.963545   \n",
            "\n",
            "             p4        g1        g2        g3        g4      stab  stabf  \\\n",
            "48572  0.350199  1.530448  1.616867 -0.244457  0.848759  2.118736      1   \n",
            "38696 -0.859414 -0.452117 -0.431227 -0.689044  0.501455 -1.575823      0   \n",
            "13611  1.471169 -0.601180  1.110587 -0.884969 -1.625643 -1.279109      0   \n",
            "35213 -1.014716 -0.876993 -1.270139 -0.833456 -1.243011 -1.106973      0   \n",
            "31766 -1.608110 -0.607596 -0.716800 -0.264250  1.662188 -0.021873      1   \n",
            "\n",
            "       time_index  \n",
            "48572           0  \n",
            "38696           1  \n",
            "13611           2  \n",
            "35213           3  \n",
            "31766           4  \n",
            "Index(['tau1', 'tau2', 'tau3', 'tau4', 'p1', 'p2', 'p3', 'p4', 'g1', 'g2',\n",
            "       'g3', 'g4', 'stab', 'stabf', 'time_index'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "print(train_df.columns)\n",
        "print(train_df.dtypes)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAhWq4Ytq2Kn",
        "outputId": "6c911efa-7ed1-411d-caeb-3b26ea2dad9d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
            "48572  1.129543  1.726514  1.059525  0.687641  1.257212 -1.493692 -1.040221   \n",
            "38696  1.693901 -0.011534 -1.531814 -1.225373 -1.190822  1.298100  1.629712   \n",
            "13611  0.931985 -1.394627 -0.591586  0.626323 -0.957030  1.087540 -0.896396   \n",
            "35213  0.914392 -1.569813  1.595629  0.763249  0.809421 -1.477911  1.086703   \n",
            "31766 -1.651294 -0.995641  0.089400  0.948869  1.887863 -0.707468 -0.963545   \n",
            "\n",
            "             p4        g1        g2        g3        g4      stab  stabf  \\\n",
            "48572  0.350199  1.530448  1.616867 -0.244457  0.848759  2.118736      1   \n",
            "38696 -0.859414 -0.452117 -0.431227 -0.689044  0.501455 -1.575823      0   \n",
            "13611  1.471169 -0.601180  1.110587 -0.884969 -1.625643 -1.279109      0   \n",
            "35213 -1.014716 -0.876993 -1.270139 -0.833456 -1.243011 -1.106973      0   \n",
            "31766 -1.608110 -0.607596 -0.716800 -0.264250  1.662188 -0.021873      1   \n",
            "\n",
            "       time_index  \n",
            "48572           0  \n",
            "38696           1  \n",
            "13611           2  \n",
            "35213           3  \n",
            "31766           4  \n",
            "Index(['tau1', 'tau2', 'tau3', 'tau4', 'p1', 'p2', 'p3', 'p4', 'g1', 'g2',\n",
            "       'g3', 'g4', 'stab', 'stabf', 'time_index'],\n",
            "      dtype='object')\n",
            "tau1          float64\n",
            "tau2          float64\n",
            "tau3          float64\n",
            "tau4          float64\n",
            "p1            float64\n",
            "p2            float64\n",
            "p3            float64\n",
            "p4            float64\n",
            "g1            float64\n",
            "g2            float64\n",
            "g3            float64\n",
            "g4            float64\n",
            "stab          float64\n",
            "stabf           int64\n",
            "time_index      int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a grouping column\n",
        "train_df['group_id'] = 0  # If there's only one group, or assign different integers for different groups\n",
        "\n",
        "from pytorch_forecasting import TimeSeriesDataSet\n",
        "\n",
        "# Define maximum lengths\n",
        "max_encoder_length = 12\n",
        "max_prediction_length = 1\n",
        "\n",
        "# Initialize TimeSeriesDataSet with grouping column\n",
        "training = TimeSeriesDataSet(\n",
        "    train_df,\n",
        "    time_idx=\"time_index\",  # Column for time index\n",
        "    target=\"stabf\",  # Target variable\n",
        "    group_ids=[\"group_id\"],  # The newly created grouping column\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    static_categoricals=[],  # If there are static categorical variables, include them here\n",
        "    time_varying_known_reals=[\n",
        "        \"tau1\", \"tau2\", \"tau3\", \"tau4\",\n",
        "        \"p1\", \"p2\", \"p3\", \"p4\",\n",
        "        \"g1\", \"g2\", \"g3\", \"g4\"\n",
        "    ],\n",
        "    time_varying_unknown_reals=[\"stab\", \"stabf\"],\n",
        ")\n"
      ],
      "metadata": {
        "id": "sJjVq_GKr7Co"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders for training and validation\n",
        "train_dataloader = training.to_dataloader(train=True, batch_size=32, num_workers=0)\n",
        "val_dataloader = training.to_dataloader(train=False, batch_size=32, num_workers=0)\n"
      ],
      "metadata": {
        "id": "5zUZDMkvsws8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Definition and Training"
      ],
      "metadata": {
        "id": "yPd4KFauuEVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer\n",
        "from pytorch_forecasting.metrics import QuantileLoss\n",
        "\n",
        "# Initialize the Temporal Fusion Transformer model with QuantileLoss\n",
        "tft = TemporalFusionTransformer.from_dataset(\n",
        "    training,\n",
        "    learning_rate=0.03,\n",
        "    hidden_size=16,  # Model hidden size\n",
        "    attention_head_size=1,\n",
        "    dropout=0.1,\n",
        "    hidden_continuous_size=8,\n",
        "    output_size=7,  # Number of quantiles for the quantile loss\n",
        "    loss=QuantileLoss(),  # Correct loss function for TFT\n",
        "    log_interval=10,\n",
        "    reduce_on_plateau_patience=4,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIvSl25St5rz",
        "outputId": "bfe35043-d0aa-4e9e-ab06-1bfda55ff75d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:143: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
            "  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR52puGluU4k",
        "outputId": "05440268-8bab-4fd0-f0e9-86b3ae0be815"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Number of GPUs:\", torch.cuda.device_count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fco6Bgwdv5B-",
        "outputId": "8ae4ac01-a8bf-4728-f137-24f82e23d4f5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "Number of GPUs: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=30,\n",
        "    accelerator='gpu',\n",
        "    devices=1  # Use the GPU if available\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcZc1rM3xuAr",
        "outputId": "04521d1c-70a7-4e67-aae9-8e6011df3f96"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in val_dataloader:\n",
        "    print(batch)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv4OUeFFyKbj",
        "outputId": "85614bba-bb2c-43a8-f76a-eefca1cc479c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'encoder_cat': tensor([], size=(32, 12, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 1.1284,  1.7278,  1.0562,  ...,  0.8507,  2.1183,  1.0000],\n",
            "         [ 1.6926, -0.0114, -1.5339,  ...,  0.5035, -1.5732,  0.0000],\n",
            "         [ 0.9309, -1.3954, -0.5941,  ..., -1.6229, -1.2767,  0.0000],\n",
            "         ...,\n",
            "         [ 0.8769, -0.4941, -1.3296,  ..., -1.4565, -1.2651,  0.0000],\n",
            "         [-1.5302,  0.7783,  1.5048,  ..., -0.3553,  0.6036,  1.0000],\n",
            "         [ 1.5098, -0.1638,  0.0106,  ...,  0.6602,  1.2990,  1.0000]],\n",
            "\n",
            "        [[ 1.6926, -0.0114, -1.5339,  ...,  0.5035, -1.5732,  0.0000],\n",
            "         [ 0.9309, -1.3954, -0.5941,  ..., -1.6229, -1.2767,  0.0000],\n",
            "         [ 0.9133, -1.5707,  1.5921,  ..., -1.2404, -1.1047,  0.0000],\n",
            "         ...,\n",
            "         [-1.5302,  0.7783,  1.5048,  ..., -0.3553,  0.6036,  1.0000],\n",
            "         [ 1.5098, -0.1638,  0.0106,  ...,  0.6602,  1.2990,  1.0000],\n",
            "         [-1.1792,  0.2430, -0.4261,  ...,  0.7695, -0.1620,  1.0000]],\n",
            "\n",
            "        [[ 0.9309, -1.3954, -0.5941,  ..., -1.6229, -1.2767,  0.0000],\n",
            "         [ 0.9133, -1.5707,  1.5921,  ..., -1.2404, -1.1047,  0.0000],\n",
            "         [-1.6517, -0.9962,  0.0866,  ...,  1.6638, -0.0205,  1.0000],\n",
            "         ...,\n",
            "         [ 1.5098, -0.1638,  0.0106,  ...,  0.6602,  1.2990,  1.0000],\n",
            "         [-1.1792,  0.2430, -0.4261,  ...,  0.7695, -0.1620,  1.0000],\n",
            "         [-1.6746, -1.2669,  1.6590,  ..., -1.1716, -1.6040,  0.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.9788,  1.3437, -0.0583,  ..., -1.4558,  0.7249,  1.0000],\n",
            "         [-1.2493,  1.4626,  0.1623,  ...,  1.2237,  0.7304,  1.0000],\n",
            "         [ 0.5991,  0.3617, -0.0138,  ..., -0.1912,  1.0276,  1.0000],\n",
            "         ...,\n",
            "         [-0.3017,  1.5687, -1.4028,  ..., -1.6065, -0.4458,  0.0000],\n",
            "         [-0.5246,  0.4624, -0.5143,  ..., -0.0100,  0.1977,  1.0000],\n",
            "         [ 1.1137, -0.5706, -0.9445,  ..., -1.3353, -1.0747,  0.0000]],\n",
            "\n",
            "        [[-1.2493,  1.4626,  0.1623,  ...,  1.2237,  0.7304,  1.0000],\n",
            "         [ 0.5991,  0.3617, -0.0138,  ..., -0.1912,  1.0276,  1.0000],\n",
            "         [ 1.0879,  1.2707, -1.4340,  ...,  1.2098,  0.2585,  1.0000],\n",
            "         ...,\n",
            "         [-0.5246,  0.4624, -0.5143,  ..., -0.0100,  0.1977,  1.0000],\n",
            "         [ 1.1137, -0.5706, -0.9445,  ..., -1.3353, -1.0747,  0.0000],\n",
            "         [-1.6609, -0.1217,  0.2654,  ...,  0.7644, -1.2392,  0.0000]],\n",
            "\n",
            "        [[ 0.5991,  0.3617, -0.0138,  ..., -0.1912,  1.0276,  1.0000],\n",
            "         [ 1.0879,  1.2707, -1.4340,  ...,  1.2098,  0.2585,  1.0000],\n",
            "         [ 1.0028,  0.3897,  0.4642,  ..., -0.8632,  0.0214,  1.0000],\n",
            "         ...,\n",
            "         [ 1.1137, -0.5706, -0.9445,  ..., -1.3353, -1.0747,  0.0000],\n",
            "         [-1.6609, -0.1217,  0.2654,  ...,  0.7644, -1.2392,  0.0000],\n",
            "         [-1.0952,  1.0461, -0.4719,  ...,  0.2041,  0.8661,  1.0000]]]), 'encoder_target': tensor([[1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
            "        [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n",
            "        [0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0],\n",
            "        [0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0],\n",
            "        [1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0],\n",
            "        [0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1],\n",
            "        [1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0],\n",
            "        [1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
            "        [1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0],\n",
            "        [0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1],\n",
            "        [1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1],\n",
            "        [1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1],\n",
            "        [1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0],\n",
            "        [0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1],\n",
            "        [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
            "        [1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0],\n",
            "        [0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1],\n",
            "        [1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
            "        [0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
            "        [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0],\n",
            "        [0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1]]), 'encoder_lengths': tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]), 'decoder_cat': tensor([], size=(32, 1, 0), dtype=torch.int64), 'decoder_cont': tensor([[[-1.1792,  0.2430, -0.4261,  1.0717, -1.0131, -0.7737,  1.2516,\n",
            "           1.2787, -1.1726, -0.5142, -1.2620,  0.7695, -0.1620,  1.0000]],\n",
            "\n",
            "        [[-1.6746, -1.2669,  1.6590,  0.4211,  0.2095,  0.0076, -0.0828,\n",
            "          -0.2886, -0.1954,  0.2580,  0.2020, -1.1716, -1.6040,  0.0000]],\n",
            "\n",
            "        [[-1.5973, -1.2964, -0.3633, -0.1327,  0.2462, -0.3252, -0.5185,\n",
            "           0.4154,  0.5841,  1.3191, -0.1722, -0.7214, -1.3370,  0.0000]],\n",
            "\n",
            "        [[ 0.5719, -0.9234, -1.0625, -1.4284,  2.3082, -1.5306, -1.1838,\n",
            "          -1.2978, -0.2525,  0.0370,  1.1544,  0.9297, -0.7781,  0.0000]],\n",
            "\n",
            "        [[-0.2760,  0.5298, -0.3959,  1.3473, -2.1064,  1.3055,  1.7087,\n",
            "           0.6467,  1.4427, -0.0984,  1.2679,  0.6229,  1.6540,  1.0000]],\n",
            "\n",
            "        [[-0.9227,  0.9135, -1.1302, -1.4495, -0.0736, -1.6890,  0.4126,\n",
            "           1.3994,  1.3611,  0.9622, -1.3661,  0.3948, -1.0305,  0.0000]],\n",
            "\n",
            "        [[-0.3558, -1.7190, -0.5956,  1.1779, -0.6809,  0.7561,  0.9404,\n",
            "          -0.5124,  0.9454, -1.0982,  0.0466,  1.6600,  0.5155,  1.0000]],\n",
            "\n",
            "        [[ 1.4015,  0.9790,  0.1196, -1.0403,  1.1219,  0.4420, -1.3454,\n",
            "          -1.0432,  0.7166, -1.6477, -0.9744,  1.2747, -0.4711,  0.0000]],\n",
            "\n",
            "        [[-1.3468,  0.5269,  1.3715, -0.9492, -0.7666,  0.4734,  0.0337,\n",
            "           0.8254, -0.3090, -0.2999,  0.5632,  1.3276, -0.3555,  1.0000]],\n",
            "\n",
            "        [[ 0.9874,  0.4176, -1.4423,  0.3258,  0.3338,  0.2852, -0.4345,\n",
            "          -0.4294,  1.5100, -0.7451,  1.4742, -0.7293,  0.0697,  1.0000]],\n",
            "\n",
            "        [[ 1.5232, -0.1975,  0.9051,  1.7005,  0.7361, -1.3337, -0.3453,\n",
            "           0.3971, -0.7901, -0.0954,  1.2986,  1.0454,  1.4242,  1.0000]],\n",
            "\n",
            "        [[ 0.4632, -0.3292, -1.6268,  0.2117, -1.0448,  0.5272,  0.4545,\n",
            "           0.8339, -0.3444, -0.2132, -1.5253,  1.3476,  0.5222,  1.0000]],\n",
            "\n",
            "        [[ 0.5494,  1.4997, -1.5096, -1.1256, -0.4647,  1.0789, -0.5793,\n",
            "           0.3106,  0.1303, -1.0940,  0.4655, -0.3992, -0.9927,  0.0000]],\n",
            "\n",
            "        [[ 1.6583, -1.3741,  0.5546,  1.2467,  0.3158, -0.6768,  0.4104,\n",
            "          -0.2842,  0.6774,  0.4721, -0.0785, -1.4657, -0.2125,  1.0000]],\n",
            "\n",
            "        [[-0.4586,  1.5596,  0.1923,  1.5267,  1.4316, -0.7469, -0.1320,\n",
            "          -1.6093,  1.5771, -0.9238,  1.1567,  0.0403,  1.1362,  1.0000]],\n",
            "\n",
            "        [[-0.4877,  0.3996, -1.5453, -0.0195, -1.9703,  0.9859,  0.9269,\n",
            "           1.5112, -0.1418,  0.0856, -0.5330, -1.5390, -1.1849,  0.0000]],\n",
            "\n",
            "        [[ 1.6865,  0.7735,  0.3258,  1.0148,  0.0279, -1.3163, -0.0358,\n",
            "           1.3001, -0.4148,  1.4859,  0.2367,  1.5339,  1.9685,  1.0000]],\n",
            "\n",
            "        [[ 0.9788,  1.3437, -0.0583,  1.0238, -0.6466,  1.6977,  0.3002,\n",
            "          -0.8703, -1.4226,  0.6456,  1.6245, -1.4558,  0.7249,  1.0000]],\n",
            "\n",
            "        [[-1.2493,  1.4626,  0.1623,  0.7385,  0.0973, -1.4625,  0.4813,\n",
            "           0.8079,  1.2142, -0.0050,  0.1876,  1.2237,  0.7304,  1.0000]],\n",
            "\n",
            "        [[ 0.5991,  0.3617, -0.0138, -0.7116, -0.0962,  0.4335, -0.5977,\n",
            "           0.3327, -1.5463,  1.5509,  0.5293, -0.1912,  1.0276,  1.0000]],\n",
            "\n",
            "        [[ 1.0879,  1.2707, -1.4340,  0.1306,  0.7976, -1.2526,  1.4651,\n",
            "          -1.6018, -0.7576, -0.0131,  0.0276,  1.2098,  0.2585,  1.0000]],\n",
            "\n",
            "        [[ 1.0028,  0.3897,  0.4642,  0.5379,  0.7896,  0.0662, -0.7281,\n",
            "          -0.7088, -1.1716, -1.6527,  0.8298, -0.8632,  0.0214,  1.0000]],\n",
            "\n",
            "        [[ 1.2990, -0.0449,  0.7024, -1.4038,  1.1099, -1.6077, -0.3902,\n",
            "           0.0661, -0.7196, -1.3024,  1.5428,  0.7838, -0.0779,  1.0000]],\n",
            "\n",
            "        [[-1.0629, -0.0604, -1.1370,  1.3259, -1.5885,  1.1645,  0.3878,\n",
            "           1.2095,  0.1765, -1.3652,  1.4675, -1.3438, -0.8833,  0.0000]],\n",
            "\n",
            "        [[-0.7771, -0.4561, -1.2775,  1.6055,  1.1574, -1.0439,  0.6191,\n",
            "          -1.5884, -1.3654, -0.5567, -0.7845,  1.5701, -0.2813,  1.0000]],\n",
            "\n",
            "        [[-1.4983,  1.2758,  0.5929,  0.5529, -0.9503,  0.4015,  0.0569,\n",
            "           1.1931,  0.8532, -1.1404, -0.6034, -0.5997, -0.9217,  0.0000]],\n",
            "\n",
            "        [[-0.3017,  1.5687, -1.4028,  1.4170,  0.9317, -0.7548, -0.4797,\n",
            "          -0.3855, -1.3042,  1.1702, -0.8790, -1.6065, -0.4458,  0.0000]],\n",
            "\n",
            "        [[-0.5246,  0.4624, -0.5143, -0.5594,  0.3390, -0.0728, -1.3023,\n",
            "           0.7866, -0.6603, -0.2600,  0.1517, -0.0100,  0.1977,  1.0000]],\n",
            "\n",
            "        [[ 1.1137, -0.5706, -0.9445, -1.5962,  1.0596, -1.3124, -0.2799,\n",
            "          -0.2513,  0.2047,  0.0118, -0.5452, -1.3353, -1.0747,  0.0000]],\n",
            "\n",
            "        [[-1.6609, -0.1217,  0.2654,  1.1171, -1.2468,  0.9820,  0.8259,\n",
            "           0.3596,  1.0872, -0.6848, -1.6956,  0.7644, -1.2392,  0.0000]],\n",
            "\n",
            "        [[-1.0952,  1.0461, -0.4719,  0.6337, -1.2712,  0.7806,  0.1923,\n",
            "           1.2367,  1.2226,  1.2788,  0.1258,  0.2041,  0.8661,  1.0000]],\n",
            "\n",
            "        [[ 0.8276, -0.8270,  0.4828,  0.1534,  1.3865, -0.8673,  0.0211,\n",
            "          -1.5640,  0.7692,  0.3383, -0.3637, -0.5698,  0.7349,  1.0000]]]), 'decoder_target': tensor([[1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1]]), 'decoder_lengths': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), 'decoder_time_idx': tensor([[12],\n",
            "        [13],\n",
            "        [14],\n",
            "        [15],\n",
            "        [16],\n",
            "        [17],\n",
            "        [18],\n",
            "        [19],\n",
            "        [20],\n",
            "        [21],\n",
            "        [22],\n",
            "        [23],\n",
            "        [24],\n",
            "        [25],\n",
            "        [26],\n",
            "        [27],\n",
            "        [28],\n",
            "        [29],\n",
            "        [30],\n",
            "        [31],\n",
            "        [32],\n",
            "        [33],\n",
            "        [34],\n",
            "        [35],\n",
            "        [36],\n",
            "        [37],\n",
            "        [38],\n",
            "        [39],\n",
            "        [40],\n",
            "        [41],\n",
            "        [42],\n",
            "        [43]]), 'groups': tensor([[0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0]]), 'target_scale': tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])}, (tensor([[1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1]]), None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model class\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define forward pass here\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = MyModel()\n",
        "\n",
        "# Load the model state dictionary\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6B-wsSI-62UG",
        "outputId": "620d48bb-2ea8-4c6d-b39c-6ab5e5fb3b22"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-8c85437903e5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the model class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Define layers here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "IhwxyHsl1kkm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define your model class\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers here\n",
        "        self.fc = nn.Linear(10, 1)  # Example layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define forward pass here\n",
        "        return self.fc(x)\n",
        "\n",
        "# Instantiate your model\n",
        "model = MyModel()\n"
      ],
      "metadata": {
        "id": "hEjVBQlv7kcc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "# Load the model (after defining the model class again)\n",
        "model = MyModel()\n",
        "model.load_state_dict(torch.load('model.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEG9Qz5w7od-",
        "outputId": "abe64082-b112-4442-d689-27cf68c487b1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-faf34632082e>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('model.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define your model class\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers here\n",
        "        self.fc = nn.Linear(10, 1)  # Example layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define forward pass here\n",
        "        return self.fc(x)\n",
        "\n",
        "# Instantiate your model\n",
        "model = MyModel()\n",
        "\n",
        "# Load the model weights with weights_only=True\n",
        "model.load_state_dict(torch.load('model.pth', weights_only=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYThJR7n7wiZ",
        "outputId": "25116ec3-d0dc-4fb7-a5a1-65cdfeab3a15"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCyuRqnC8ozu",
        "outputId": "1ca4c738-c2a4-4399-ba30-e5872d00a453"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model class (match this with your actual model architecture)\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc = nn.Linear(10, 1)  # Example layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Instantiate and load the model\n",
        "model = MyModel()\n",
        "model.load_state_dict(torch.load('model.pth', weights_only=True))\n",
        "model.eval()\n",
        "\n",
        "# Prepare test data (make sure the shape matches the input dimension of the model)\n",
        "test_data = torch.randn(1, 10)  # Example test data\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    predictions = model(test_data)\n",
        "\n",
        "print(\"Model Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dmfayIs84V0",
        "outputId": "34326a16-c2c2-488b-b804-006e7a0cb7a7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Predictions: tensor([[-0.5010]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the model class\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc = nn.Linear(10, 2)  # 2 output features for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = MyModel()\n"
      ],
      "metadata": {
        "id": "S-11vLpb9STt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n"
      ],
      "metadata": {
        "id": "4eA7-wuJ-Spe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "0tZRFc1U-X95"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_input = torch.randn(1, 10)  # Adjust input size as needed\n",
        "    output = model(sample_input)\n",
        "\n",
        "    # For binary classification:\n",
        "    predictions = torch.sigmoid(output)\n",
        "\n",
        "    # For multi-class classification:\n",
        "    predictions = torch.softmax(output, dim=1)\n",
        "\n",
        "    print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiAN_fyz-cjg",
        "outputId": "46d43113-9517-4f5d-a9c3-8887eddee235"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6084, 0.3916]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc = nn.Linear(10, 1)  # Single output unit\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "GJJMUhL8-i7G"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model = MyModel()\n",
        "criterion = nn.BCEWithLogitsLoss()  # For binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Dummy data for illustration (replace with your actual data)\n",
        "inputs = torch.randn(100, 10)  # Example input tensor\n",
        "labels = torch.randint(0, 2, (100, 1)).float()  # Example labels tensor for binary classification\n"
      ],
      "metadata": {
        "id": "Je1B6S_j-riY"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc = nn.Linear(10, 2)  # Two output units for two classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "QXVZ-Gmc_err"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model = MyModel()\n",
        "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Dummy data for illustration (replace with your actual data)\n",
        "inputs = torch.randn(100, 10)  # Example input tensor\n",
        "labels = torch.randint(0, 2, (100,))  # Example labels tensor for two classes (class indices)\n"
      ],
      "metadata": {
        "id": "ePBuMDPS_nrT"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy_binary(outputs, labels):\n",
        "    # Apply sigmoid to get probabilities\n",
        "    probs = torch.sigmoid(outputs)\n",
        "    # Get predictions (0 or 1)\n",
        "    predictions = (probs > 0.5).float()\n",
        "    # Calculate accuracy\n",
        "    correct = (predictions == labels).float().sum()\n",
        "    accuracy = correct / labels.size(0)\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "7e2K_OAb_tUR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy_multi(outputs, labels):\n",
        "    # Get predicted class (index of max logit)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    # Calculate accuracy\n",
        "    correct = (predictions == labels).float().sum()\n",
        "    accuracy = correct / labels.size(0)\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "L444HerkALHx"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Outputs shape:', outputs.shape)\n",
        "print('Labels shape:', labels.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "513DwStNAPYA",
        "outputId": "26a3fe6f-5c85-481a-9a71-cb91da73d317"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs shape: torch.Size([100, 2])\n",
            "Labels shape: torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "d5K6NJjNAUu_"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy_multiclass(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
        "    correct = (predicted == labels).float().sum()\n",
        "    accuracy = correct / labels.size(0)\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "a5zUNsD_BZ4L"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10  # Define the number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = calculate_accuracy_multiclass(outputs, labels)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}, Accuracy: {accuracy.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y16OojmtBgF8",
        "outputId": "9a3d7a1d-23db-483d-f1c1-22c9edfd3fa8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8771549463272095, Accuracy: 0.5\n",
            "Epoch [2/10], Loss: 0.8754751682281494, Accuracy: 0.49000000953674316\n",
            "Epoch [3/10], Loss: 0.8738045692443848, Accuracy: 0.49000000953674316\n",
            "Epoch [4/10], Loss: 0.872143030166626, Accuracy: 0.49000000953674316\n",
            "Epoch [5/10], Loss: 0.8704909682273865, Accuracy: 0.49000000953674316\n",
            "Epoch [6/10], Loss: 0.8688482046127319, Accuracy: 0.49000000953674316\n",
            "Epoch [7/10], Loss: 0.8672152757644653, Accuracy: 0.49000000953674316\n",
            "Epoch [8/10], Loss: 0.8655921220779419, Accuracy: 0.49000000953674316\n",
            "Epoch [9/10], Loss: 0.8639788031578064, Accuracy: 0.49000000953674316\n",
            "Epoch [10/10], Loss: 0.8623754978179932, Accuracy: 0.49000000953674316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Sample data generation\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert data to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Define a more complex model\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 50)\n",
        "        self.fc2 = nn.Linear(50, 2)  # Output layer with 2 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, criterion, and optimizer\n",
        "model = MyModel()\n",
        "criterion = nn.CrossEntropyLoss()  # For classification with 2 classes\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "# DataLoader setup\n",
        "train_data = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total = y_test_tensor.size(0)\n",
        "    correct = (predicted == y_test_tensor).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Final Test Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgbgU0wvBk0f",
        "outputId": "7667f6a0-e02f-422c-821a-b5634bfc3862"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6902, Accuracy: 0.5243\n",
            "Epoch [2/10], Loss: 0.6221, Accuracy: 0.7157\n",
            "Epoch [3/10], Loss: 0.5662, Accuracy: 0.8257\n",
            "Epoch [4/10], Loss: 0.5189, Accuracy: 0.8529\n",
            "Epoch [5/10], Loss: 0.4784, Accuracy: 0.8614\n",
            "Epoch [6/10], Loss: 0.4454, Accuracy: 0.8629\n",
            "Epoch [7/10], Loss: 0.4174, Accuracy: 0.8657\n",
            "Epoch [8/10], Loss: 0.3928, Accuracy: 0.8700\n",
            "Epoch [9/10], Loss: 0.3738, Accuracy: 0.8729\n",
            "Epoch [10/10], Loss: 0.3571, Accuracy: 0.8771\n",
            "Final Test Accuracy: 0.8667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'trained_model.pth')\n"
      ],
      "metadata": {
        "id": "tvlLtIqJCg2X"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ObVPeF84DM9H"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDRw08YcDya_",
        "outputId": "59333080-97ab-4336-acc6-33aff41f08f6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"Directbookstore\"\n",
        "!git config --global user.email \"directbookstoreltd@gmail.com\"\n"
      ],
      "metadata": {
        "id": "m9Qv81vED7b-"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Directbookstore/TFT-renewable-Energy-fault-prediction-.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqIC24FhGOk3",
        "outputId": "18d5deaf-0bc8-43ad-b73f-78747e207dc0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TFT-renewable-Energy-fault-prediction-'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TFT-renewable-Energy-fault-prediction-\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3J6V67FIC38",
        "outputId": "d005b688-c109-4fb3-8cad-4ad2d59792f6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TFT-renewable-Energy-fault-prediction-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n"
      ],
      "metadata": {
        "id": "qFKXPpSEIgxv"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"my first fault prediction\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52KBH1BqIqgM",
        "outputId": "7279fd54-e8e9-4581-b4af-7d508ac58701"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QUrRlTOI8u0",
        "outputId": "dacd6995-c22b-4076-e375-712bb79dc938"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "LYzh9X_aJDzO"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download()  # Replace with your file path\n",
        "\n"
      ],
      "metadata": {
        "id": "e_oTAdhrLoK6"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "1CJ8eSZnMFC9"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oooorqfFMqLX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}